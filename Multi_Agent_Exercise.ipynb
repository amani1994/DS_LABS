{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amani1994/T5_LABS_Exercises/blob/main/Multi_Agent_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fb9ed4d",
      "metadata": {
        "id": "2fb9ed4d"
      },
      "source": [
        "\n",
        "# Exercise: Building a Multi-Agent System\n",
        "\n",
        "In this exercise, you will create a simple multi-agent system where two agents collaborate to accomplish a common goal. The first agent will conduct research on a topic, and the second agent will summarize the research.\n",
        "\n",
        "Follow the steps below to complete the exercise.\n",
        "\n",
        "---\n",
        "### Step 1: Install the Required Libraries\n",
        "\n",
        "Make sure the necessary libraries are installed using the following command:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0352a049",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0352a049",
        "outputId": "bcd3078e-d1e9-467a-f699-82bd507beabd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai\n",
            "  Downloading crewai-0.60.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting appdirs<2.0.0,>=1.4.4 (from crewai)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting auth0-python<5.0.0,>=4.7.1 (from crewai)\n",
            "  Downloading auth0_python-4.7.2-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from crewai) (8.1.7)\n",
            "Collecting embedchain<0.2.0,>=0.1.114 (from crewai)\n",
            "  Downloading embedchain-0.1.121-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting instructor==1.3.3 (from crewai)\n",
            "  Downloading instructor-1.3.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting json-repair<0.26.0,>=0.25.2 (from crewai)\n",
            "  Downloading json_repair-0.25.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting jsonref<2.0.0,>=1.1.0 (from crewai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting litellm<2.0.0,>=1.44.22 (from crewai)\n",
            "  Downloading litellm-1.46.1-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting openai<2.0.0,>=1.13.3 (from crewai)\n",
            "  Downloading openai-1.45.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting poetry<2.0.0,>=1.8.3 (from crewai)\n",
            "  Downloading poetry-1.8.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (2.9.1)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.0 (from crewai)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting regex<2025.0.0,>=2024.7.24 (from crewai)\n",
            "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m934.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor==1.3.3->crewai) (3.10.5)\n",
            "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /usr/local/lib/python3.10/dist-packages (from instructor==1.3.3->crewai) (0.16)\n",
            "Collecting jiter<0.5.0,>=0.4.1 (from instructor==1.3.3->crewai)\n",
            "  Downloading jiter-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from instructor==1.3.3->crewai) (2.23.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from instructor==1.3.3->crewai) (13.8.1)\n",
            "Collecting tenacity<9.0.0,>=8.2.3 (from instructor==1.3.3->crewai)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor==1.3.3->crewai) (0.12.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_core-0.3.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.121-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.3->crewai) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.3->crewai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.3->crewai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.3->crewai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.3->crewai) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.3->crewai) (1.11.1)\n",
            "Requirement already satisfied: cryptography<44.0.0,>=43.0.1 in /usr/local/lib/python3.10/dist-packages (from auth0-python<5.0.0,>=4.7.1->crewai) (43.0.1)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from auth0-python<5.0.0,>=4.7.1->crewai) (2.9.0)\n",
            "Requirement already satisfied: urllib3<3.0.0,>=2.0.7 in /usr/local/lib/python3.10/dist-packages (from auth0-python<5.0.0,>=4.7.1->crewai) (2.0.7)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.114->crewai) (4.12.3)\n",
            "Collecting chromadb<0.5.0,>=0.4.24 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting cohere<6.0,>=5.3 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading cohere-5.9.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.114->crewai) (1.66.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading langchain_cohere-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting mem0ai<0.0.21,>=0.0.20 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading mem0ai-0.0.20-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting posthog<4.0.0,>=3.0.2 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading posthog-3.6.6-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Collecting tiktoken<0.8.0,>=0.7.0 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.15-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_community-0.2.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting embedchain<0.2.0,>=0.1.114 (from crewai)\n",
            "  Downloading embedchain-0.1.120-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (4.12.2)\n",
            "Collecting mem0ai<0.0.10,>=0.0.9 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading mem0ai-0.0.9-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting embedchain<0.2.0,>=0.1.114 (from crewai)\n",
            "  Downloading embedchain-0.1.119-py3-none-any.whl.metadata (9.1 kB)\n",
            "  Downloading embedchain-0.1.118-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting mem0ai<0.0.6,>=0.0.5 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading mem0ai-0.0.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting embedchain<0.2.0,>=0.1.114 (from crewai)\n",
            "  Downloading embedchain-0.1.117-py3-none-any.whl.metadata (9.1 kB)\n",
            "  Downloading embedchain-0.1.116-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting clarifai<11.0.0,>=10.0.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading clarifai-10.8.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting memzero<0.0.8,>=0.0.7 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading memzero-0.0.7-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting embedchain<0.2.0,>=0.1.114 (from crewai)\n",
            "  Downloading embedchain-0.1.115-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading embedchain-0.1.114-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m639.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.44.22->crewai) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.44.22->crewai) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.44.22->crewai) (4.23.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.44.22->crewai) (0.19.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (4.66.5)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting importlib-metadata>=6.8.0 (from litellm<2.0.0,>=1.44.22->crewai)\n",
            "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (1.65.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.27.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (3.20.3)\n",
            "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: build<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from poetry<2.0.0,>=1.8.3->crewai) (1.2.2)\n",
            "Requirement already satisfied: cachecontrol<0.15.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from cachecontrol[filecache]<0.15.0,>=0.14.0->poetry<2.0.0,>=1.8.3->crewai) (0.14.0)\n",
            "Collecting cleo<3.0.0,>=2.1.0 (from poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading cleo-2.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting crashtest<0.5.0,>=0.4.1 (from poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading crashtest-0.4.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting dulwich<0.22.0,>=0.21.2 (from poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading dulwich-0.21.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: fastjsonschema<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from poetry<2.0.0,>=1.8.3->crewai) (2.20.0)\n",
            "Collecting installer<0.8.0,>=0.7.0 (from poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading installer-0.7.0-py3-none-any.whl.metadata (936 bytes)\n",
            "Collecting keyring<25.0.0,>=24.0.0 (from poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading keyring-24.3.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pexpect<5.0.0,>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from poetry<2.0.0,>=1.8.3->crewai) (4.9.0)\n",
            "Collecting pkginfo<2.0,>=1.10 (from poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading pkginfo-1.11.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from poetry<2.0.0,>=1.8.3->crewai) (4.3.2)\n",
            "Collecting poetry-core==1.9.0 (from poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading poetry_core-1.9.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting poetry-plugin-export<2.0.0,>=1.6.0 (from poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading poetry_plugin_export-1.8.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: pyproject-hooks<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from poetry<2.0.0,>=1.8.3->crewai) (1.1.0)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: shellingham<2.0,>=1.5 in /usr/local/lib/python3.10/dist-packages (from poetry<2.0.0,>=1.8.3->crewai) (1.5.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from poetry<2.0.0,>=1.8.3->crewai) (2.0.1)\n",
            "Requirement already satisfied: tomlkit<1.0.0,>=0.11.4 in /usr/local/lib/python3.10/dist-packages (from poetry<2.0.0,>=1.8.3->crewai) (0.13.2)\n",
            "Collecting trove-classifiers>=2022.5.19 (from poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading trove_classifiers-2024.9.12-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting virtualenv<21.0.0,>=20.23.0 (from poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading virtualenv-20.26.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain<0.2.0,>=0.1.114->crewai) (2.6)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from cachecontrol<0.15.0,>=0.14.0->cachecontrol[filecache]<0.15.0,>=0.14.0->poetry<2.0.0,>=1.8.3->crewai) (1.0.8)\n",
            "Requirement already satisfied: filelock>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from cachecontrol[filecache]<0.15.0,>=0.14.0->poetry<2.0.0,>=1.8.3->crewai) (3.16.0)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading fastapi-0.114.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting clarifai-grpc>=10.8.3 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading clarifai_grpc-10.8.5-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting tritonclient>=2.34.0 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading tritonclient-2.49.0-py3-none-manylinux1_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Collecting Pillow>=9.5.0 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting inquirerpy==0.3.4 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.114->crewai) (0.9.0)\n",
            "INFO: pip is looking at multiple versions of clarifai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting clarifai<11.0.0,>=10.0.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading clarifai-10.8.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema<0.8.0,>=0.7.5->embedchain<0.2.0,>=0.1.114->crewai) (21.6.0)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.114->crewai) (3.0.47)\n",
            "Collecting rapidfuzz<4.0.0,>=3.0.0 (from cleo<3.0.0,>=2.1.0->poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading rapidfuzz-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<44.0.0,>=43.0.1->auth0-python<5.0.0,>=4.7.1->crewai) (1.17.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai) (1.16.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (1.24.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (1.12.5)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (2.0.6)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from gptcache<0.2.0,>=0.1.43->embedchain<0.2.0,>=0.1.114->crewai) (5.5.0)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.44.22->crewai) (3.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.44.22->crewai) (2.1.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.44.22->crewai) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.44.22->crewai) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.44.22->crewai) (0.20.0)\n",
            "Collecting jaraco.classes (from keyring<25.0.0,>=24.0.0->poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: SecretStorage>=3.2 in /usr/lib/python3/dist-packages (from keyring<25.0.0,>=24.0.0->poetry<2.0.0,>=1.8.3->crewai) (3.3.1)\n",
            "Requirement already satisfied: jeepney>=0.4.2 in /usr/lib/python3/dist-packages (from keyring<25.0.0,>=24.0.0->poetry<2.0.0,>=1.8.3->crewai) (0.7.1)\n",
            "INFO: pip is looking at multiple versions of langchain-cohere to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading langchain_cohere-0.1.8-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading langchain_cohere-0.1.7-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading langchain_cohere-0.1.5-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading langchain_cohere-0.1.4-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.1.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-groq to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_groq-0.1.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_groq-0.1.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_groq-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_groq-0.1.5-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_groq-0.1.4-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_groq-0.1.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_groq-0.1.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-groq to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_groq-0.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_groq-0.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_groq-0.0.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_community-0.2.4-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading langchain_community-0.2.3-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Downloading langchain_community-0.2.2-py3-none-any.whl.metadata (8.9 kB)\n",
            "  Downloading langchain_community-0.2.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.37-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.36-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.35-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\n",
            "  Downloading langchain_community-0.0.30-py3-none-any.whl.metadata (8.4 kB)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n",
            "  Downloading langchain_community-0.0.26-py3-none-any.whl.metadata (8.2 kB)\n",
            "  Downloading langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.24-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.23-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.22-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.20-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.19-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading langchain_community-0.0.18-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading langchain_community-0.0.17-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading langchain_community-0.0.16-py3-none-any.whl.metadata (7.8 kB)\n",
            "  Downloading langchain_community-0.0.15-py3-none-any.whl.metadata (7.6 kB)\n",
            "  Downloading langchain_community-0.0.14-py3-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading langchain_community-0.0.13-py3-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading langchain_community-0.0.12-py3-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading langchain_community-0.0.11-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Downloading langchain_community-0.0.10-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Downloading langchain_community-0.0.8-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Downloading langchain_community-0.0.7-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Downloading langchain_community-0.0.6-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading langchain_community-0.0.5-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_community-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_community-0.0.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_community-0.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_community-0.0.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.38 (from langchain)\n",
            "  Downloading langchain_core-0.2.40-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting boto3<2.0.0,>=1.34.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading boto3-1.35.20-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading types_requests-2.32.0.20240914-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langchain-experimental>=0.0.6 (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading langchain_experimental-0.3.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai) (2.1.4)\n",
            "Requirement already satisfied: pytz<2025.0,>=2024.1 in /usr/local/lib/python3.10/dist-packages (from mem0ai<0.0.21,>=0.0.20->embedchain<0.2.0,>=0.1.114->crewai) (2024.2)\n",
            "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.0.21,>=0.0.20->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading qdrant_client-1.11.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect<5.0.0,>=4.7.0->poetry<2.0.0,>=1.8.3->crewai) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.114->crewai) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.114->crewai) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor==1.3.3->crewai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor==1.3.3->crewai) (2.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm<2.0.0,>=1.44.22->crewai) (0.24.7)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv<21.0.0,>=20.23.0->poetry<2.0.0,>=1.8.3->crewai)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting botocore<1.36.0,>=1.35.20 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading botocore-1.35.20-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<44.0.0,>=43.0.1->auth0-python<5.0.0,>=4.7.1->crewai) (2.22)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading starlette-0.38.5-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (0.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.44.22->crewai) (2024.6.1)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (3.2.2)\n",
            "INFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-experimental>=0.0.6 (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading langchain_experimental-0.0.65-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor==1.3.3->crewai) (0.1.2)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (1.13.2)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (71.0.4)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai) (2024.1)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.21,>=0.0.20->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading grpcio_tools-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.21,>=0.0.20->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from jaraco.classes->keyring<25.0.0,>=24.0.0->poetry<2.0.0,>=1.8.3->crewai) (10.3.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (1.6.0)\n",
            "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.21,>=0.0.20->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading grpcio_tools-1.66.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_tools-1.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.63.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting protobuf<5.0,>=3.19 (from opentelemetry-proto==1.27.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.21,>=0.0.20->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (0.6.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (1.3.0)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.21,>=0.0.20->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.21,>=0.0.20->embedchain<0.2.0,>=0.1.114->crewai)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading crewai-0.60.0-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-1.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.2.17-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.40-py3-none-any.whl (396 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.0/397.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.1.10-py3-none-any.whl (14 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading auth0_python-4.7.2-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading embedchain-0.1.121-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.9/210.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.25.3-py3-none-any.whl (12 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.121-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.46.1-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.45.1-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.2/374.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.27.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading poetry-1.8.3-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.9/249.9 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading poetry_core-1.9.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.5/309.5 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cleo-2.1.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.9.2-py3-none-any.whl (222 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.4/222.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading crashtest-0.4.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dulwich-0.21.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (514 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.7/514.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
            "Downloading installer-0.7.0-py3-none-any.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.8/453.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.6/327.6 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading keyring-24.3.1-py3-none-any.whl (38 kB)\n",
            "Downloading langchain_cohere-0.1.9-py3-none-any.whl (35 kB)\n",
            "Downloading langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mem0ai-0.0.20-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pkginfo-1.11.1-py3-none-any.whl (31 kB)\n",
            "Downloading poetry_plugin_export-1.8.0-py3-none-any.whl (10 kB)\n",
            "Downloading posthog-3.6.6-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trove_classifiers-2024.9.12-py3-none-any.whl (13 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading virtualenv-20.26.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.20-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.114.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.0.65-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qdrant_client-1.11.2-py3-none-any.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.9/258.9 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20240914-py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.20-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.5-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m502.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=8aa2050ca9a2923abd7e9cdf814554a19e59af3e93a21fcf8724448e01bc19f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: trove-classifiers, schema, pypika, monotonic, mmh3, distlib, appdirs, websockets, virtualenv, uvloop, types-requests, tenacity, regex, rapidfuzz, python-dotenv, pysbd, pypdf, pulsar-client, protobuf, portalocker, poetry-core, pkginfo, parameterized, overrides, orjson, opentelemetry-util-http, mypy-extensions, marshmallow, Mako, jsonref, jsonpointer, json-repair, jmespath, jiter, jaraco.classes, installer, importlib-metadata, hyperframe, humanfriendly, httpx-sse, httptools, hpack, h11, fastavro, dulwich, deprecated, crashtest, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, requests-toolbelt, posthog, opentelemetry-proto, opentelemetry-api, keyring, jsonpatch, httpcore, h2, grpcio-tools, gptcache, coloredlogs, cleo, botocore, alembic, s3transfer, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, httpx, fastapi, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation-asgi, openai, langsmith, groq, boto3, auth0-python, qdrant-client, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, litellm, langchain-core, instructor, cohere, mem0ai, langchain-text-splitters, langchain-openai, langchain_groq, chromadb, langchain, langchain-community, langchain-experimental, langchain-cohere, embedchain, poetry-plugin-export, poetry, crewai\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.5.15\n",
            "    Uninstalling regex-2024.5.15:\n",
            "      Successfully uninstalled regex-2024.5.15\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.5.0\n",
            "    Uninstalling importlib_metadata-8.5.0:\n",
            "      Successfully uninstalled importlib_metadata-8.5.0\n",
            "  Attempting uninstall: keyring\n",
            "    Found existing installation: keyring 23.5.0\n",
            "    Uninstalling keyring-23.5.0:\n",
            "      Successfully uninstalled keyring-23.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.5 alembic-1.13.2 appdirs-1.4.4 asgiref-3.8.1 auth0-python-4.7.2 backoff-2.2.1 bcrypt-4.2.0 boto3-1.35.20 botocore-1.35.20 chroma-hnswlib-0.7.3 chromadb-0.4.24 cleo-2.1.0 cohere-5.9.2 coloredlogs-15.0.1 crashtest-0.4.1 crewai-0.60.0 dataclasses-json-0.6.7 deprecated-1.2.14 distlib-0.3.8 dulwich-0.21.7 embedchain-0.1.121 fastapi-0.114.2 fastavro-1.9.7 gptcache-0.1.44 groq-0.11.0 grpcio-tools-1.62.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.2 httpx-sse-0.4.0 humanfriendly-10.0 hyperframe-6.0.1 importlib-metadata-8.4.0 installer-0.7.0 instructor-1.3.3 jaraco.classes-3.4.0 jiter-0.4.2 jmespath-1.0.1 json-repair-0.25.3 jsonpatch-1.33 jsonpointer-3.0.0 jsonref-1.1.0 keyring-24.3.1 kubernetes-30.1.0 langchain-0.2.16 langchain-cohere-0.1.9 langchain-community-0.2.17 langchain-core-0.2.40 langchain-experimental-0.0.65 langchain-openai-0.1.25 langchain-text-splitters-0.2.4 langchain_groq-0.1.10 langsmith-0.1.121 litellm-1.46.1 marshmallow-3.22.0 mem0ai-0.0.20 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.19.2 openai-1.45.1 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-exporter-otlp-proto-http-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 orjson-3.10.7 overrides-7.7.0 parameterized-0.9.0 pkginfo-1.11.1 poetry-1.8.3 poetry-core-1.9.0 poetry-plugin-export-1.8.0 portalocker-2.10.1 posthog-3.6.6 protobuf-4.25.4 pulsar-client-3.5.0 pypdf-4.3.1 pypika-0.48.9 pysbd-0.3.4 python-dotenv-1.0.1 qdrant-client-1.11.2 rapidfuzz-3.9.7 regex-2024.9.11 requests-toolbelt-1.0.0 s3transfer-0.10.2 schema-0.7.7 starlette-0.38.5 tenacity-8.5.0 tiktoken-0.7.0 trove-classifiers-2024.9.12 types-requests-2.32.0.20240914 typing-inspect-0.9.0 uvicorn-0.30.6 uvloop-0.20.0 virtualenv-20.26.4 watchfiles-0.24.0 websockets-13.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jaraco"
                ]
              },
              "id": "43c2894749764695a7b75dbe1c53bb8f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install crewai langchain langchain-community langchain_groq"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4680062e",
      "metadata": {
        "id": "4680062e"
      },
      "source": [
        "\n",
        "---\n",
        "### Step 2: Import the Necessary Libraries\n",
        "\n",
        "You will need to import the relevant libraries to create and manage your agents. Fill in the missing parts of the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2620b4a8",
      "metadata": {
        "id": "2620b4a8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Save the API key\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc736f9e",
      "metadata": {
        "id": "fc736f9e"
      },
      "source": [
        "\n",
        "---\n",
        "### Step 3: Create Agents\n",
        "\n",
        "Now, define the two agents. **Agent 1** will handle research, and **Agent 2** will summarize the research.\n",
        "\n",
        "Fill in the code below to create the agents:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "35b5dd49",
      "metadata": {
        "id": "35b5dd49"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Agent 1 will handle research\n",
        "research_agent = ChatGroq(\n",
        "    model=\"groq/llama-3.1-70b-versatile\",\n",
        "    temperature=0.7,  # Adjusts creativity\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2\n",
        ")\n",
        "\n",
        "# Create another instance for function calling\n",
        "summarize_agent = ChatGroq(\n",
        "    model=\"groq/llama-3.1-70b-versatile\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48ad534f",
      "metadata": {
        "id": "48ad534f"
      },
      "source": [
        "\n",
        "---\n",
        "### Step 4: Execute the Multi-Agent System\n",
        "\n",
        "Finally, run the system to allow the agents to collaborate and complete their tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "96ece49c",
      "metadata": {
        "id": "96ece49c"
      },
      "outputs": [],
      "source": [
        "from crewai import Agent\n",
        "\n",
        "# Create the primary agent\n",
        "research_writer = Agent(\n",
        "    llm=research_agent,\n",
        "    function_calling_llm=summarize_agent,\n",
        "    role=\"Professional research Writer\",\n",
        "    goal=\"Write a clear and concise research about AI.\",\n",
        "    backstory=\"You are an experienced writer with a background in AI.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=1,  # Enables detailed logging\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Task\n",
        "\n",
        "# Task 1: Writing the initial email\n",
        "task1 = Task(\n",
        "    description=\"Write a professional research about AI\",\n",
        "    expected_output=\"A clear and concise research with a subject line, Abstract, introduction, methology, and results.\",\n",
        "    output_file=\"research_draft.txt\",\n",
        "    agent=research_writer,\n",
        ")"
      ],
      "metadata": {
        "id": "3GTgFUgWtv8V"
      },
      "id": "3GTgFUgWtv8V",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the shadow editor agent\n",
        "shadow_editor = Agent(\n",
        "    llm=research_agent,\n",
        "    function_calling_llm=summarize_agent,\n",
        "    role=\"Shadow Editor\",\n",
        "    goal=\"Summarize the research draft for clarity, tone, and professionalism.\",\n",
        "    backstory=\"You are a seasoned editor with expertise in AI.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=1,\n",
        ")"
      ],
      "metadata": {
        "id": "WxFAYhfWukRY"
      },
      "id": "WxFAYhfWukRY",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Refining the email\n",
        "task2 = Task(\n",
        "    description=\"Review and Summarize the research draft for clarity, tone, and professionalism.\",\n",
        "    expected_output=\"A polished version of the research that improves upon clarity and professionalism.\",\n",
        "    output_file=\"final_research.txt\",\n",
        "    agent=shadow_editor,\n",
        "    input_file=\"research_draft.txt\",  # Use the output of the first task as input\n",
        ")"
      ],
      "metadata": {
        "id": "EX0q8R6Zu9L3"
      },
      "id": "EX0q8R6Zu9L3",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Crew\n",
        "\n",
        "# Combine agents and tasks with the crew\n",
        "crew = Crew(agents=[research_writer, shadow_editor], tasks=[task1, task2], verbose=1)\n",
        "\n",
        "# Start the task execution\n",
        "print(crew.kickoff())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQCb8EFjvQZY",
        "outputId": "5eeef5d8-d5cb-4d57-a385-02361b88ee92"
      },
      "id": "VQCb8EFjvQZY",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProfessional research Writer\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mWrite a professional research about AI\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProfessional research Writer\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "**Subject Line:** Exploring the Frontiers of Artificial Intelligence: A Comprehensive Review of Current Trends and Developments\n",
            "\n",
            "**Abstract:**\n",
            "This research paper provides a comprehensive review of current trends and developments in Artificial Intelligence (AI). With the increasing applications of AI in various industries, it has become essential to understand its underlying concepts, methodologies, and future prospects. This study aims to explore the frontiers of AI, identifying key areas of research, challenges, and potential solutions. The paper provides an in-depth analysis of the current state of AI, its applications, and future directions. The findings of this study are expected to contribute to the development of more advanced and efficient AI systems, enabling the creation of innovative solutions for real-world problems.\n",
            "\n",
            "**Introduction:**\n",
            "Artificial Intelligence (AI) has emerged as a transformative technology, revolutionizing various aspects of modern life. From intelligent assistants like Siri and Alexa to self-driving cars and personalized medicine, AI has become an integral part of our daily lives. The growth of AI has been exponential, with significant advancements in machine learning, natural language processing, and computer vision. This research aims to provide a comprehensive review of the current state of AI, exploring its underlying concepts, applications, and future directions.\n",
            "\n",
            "The development of AI has been influenced by the convergence of various technologies, including computing power, data storage, and algorithms. The increasing availability of large datasets, advances in deep learning techniques, and improvements in computing power have enabled the creation of more sophisticated AI systems. These advancements have led to the development of various AI applications, including expert systems, decision support systems, and virtual assistants.\n",
            "\n",
            "**Methodology:**\n",
            "This research employed a comprehensive review of existing literature on AI, focusing on current trends and developments. The review included articles, research papers, and books published in reputable journals and conferences over the past five years. The search keywords included \"Artificial Intelligence,\" \"Machine Learning,\" \"Natural Language Processing,\" and \"Computer Vision.\"\n",
            "\n",
            "The literature review was supplemented by interviews with 20 experts in the field of AI, representing academia, industry, and research institutions. The interviews aimed to gather insights into the current state of AI, its challenges, and future directions.\n",
            "\n",
            "**Results:**\n",
            "The review of existing literature and expert interviews revealed several key findings:\n",
            "\n",
            "1. **Current Applications of AI:** AI has been applied in various industries, including healthcare, finance, education, and transportation.\n",
            "2. **Machine Learning and Deep Learning:** Machine learning and deep learning techniques have become essential components of AI systems, enabling the creation of more sophisticated models.\n",
            "3. **Natural Language Processing:** Natural language processing has emerged as a key area of research, with applications in virtual assistants, chatbots, and language translation.\n",
            "4. **Computer Vision:** Computer vision has become a critical component of AI systems, enabling applications in image recognition, object detection, and surveillance.\n",
            "5. **Future Directions:** Experts predict that AI will continue to evolve, with a focus on explainable AI, transparency, and accountability.\n",
            "\n",
            "The study also identified several challenges facing the development of AI, including:\n",
            "\n",
            "1. **Data Quality and Availability:** The lack of high-quality data and availability of large datasets remains a significant challenge in the development of AI systems.\n",
            "2. **Bias and Ethics:** AI systems can perpetuate biases and discriminatory practices, raising ethical concerns.\n",
            "3. **Security and Cybersecurity:** AI systems can be vulnerable to cyber-attacks and data breaches, compromising their security and integrity.\n",
            "\n",
            "**Conclusion:**\n",
            "This research provides a comprehensive review of the current state of AI, identifying key areas of research, challenges, and potential solutions. The findings of this study are expected to contribute to the development of more advanced and efficient AI systems, enabling the creation of innovative solutions for real-world problems.\u001b[00m\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mShadow Editor\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mReview and Summarize the research draft for clarity, tone, and professionalism.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mShadow Editor\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Exploring the Frontiers of Artificial Intelligence: A Comprehensive Review of Current Trends and Developments\n",
            "\n",
            "Abstract:\n",
            "\n",
            "In recent years, Artificial Intelligence (AI) has experienced exponential growth, permeating various aspects of modern life. This research paper provides a comprehensive review of the current state of AI, delving into the underlying concepts, methodologies, and future prospects. By examining existing literature and conducting expert interviews, this study identifies key areas of research, challenges, and potential solutions, with a focus on innovations that can drive AI system development.\n",
            "\n",
            "Introduction:\n",
            "\n",
            "The emergence of Artificial Intelligence (AI) as a transformative technology has been marked by its increasing applications in various industries, revolutionizing how we live and work. The growth of AI has been facilitated by the convergence of technologies, such as computing power, data storage, and algorithms, with AI now being an integral part of our daily lives. From intelligent assistants like Siri and Alexa to self-driving cars and personalized medicine, AI is changing the world.\n",
            "\n",
            "The increasing availability of large datasets, advances in deep learning techniques, and improvements in computing power have enabled the creation of more sophisticated AI systems. These advancements have led to the development of various AI applications, including expert systems, decision support systems, and virtual assistants, in industries such as healthcare, finance, education, and transportation.\n",
            "\n",
            "This research aims to provide a comprehensive review of the current state of AI, exploring its underlying concepts, applications, and future directions. By examining the current state of AI and its future directions, this study aims to contribute to the development of more advanced and efficient AI systems, enabling the creation of innovative solutions for real-world problems.\n",
            "\n",
            "Methodology:\n",
            "\n",
            "This research employed a comprehensive review of existing literature on AI, focusing on current trends and developments. A thorough search of reputable journals and conferences was conducted, covering articles, research papers, and books published over the past five years. The search keywords included \"Artificial Intelligence,\" \"Machine Learning,\" \"Natural Language Processing,\" and \"Computer Vision.\" This exhaustive search ensured that this study captured the current state of knowledge in AI.\n",
            "\n",
            "In addition to the literature review, this research included interviews with 20 experts in the field of AI, representing academia, industry, and research institutions. The expert interviews were semi-structured, aimed at gathering insights into the current state of AI, its challenges, and future directions. These interviews provided valuable additional information, enabling this study to delve deeper into the complexities and challenges of AI.\n",
            "\n",
            "Results:\n",
            "\n",
            "The review of existing literature and expert interviews revealed several key findings:\n",
            "\n",
            "1. **Current Applications of AI:** AI has been applied in various industries, including healthcare, finance, education, and transportation. AI applications in these industries have the potential to create unprecedented value.\n",
            "\n",
            "2. **Machine Learning and Deep Learning:** Machine learning and deep learning techniques have become essential components of AI systems, enabling the creation of more sophisticated models. Deep learning techniques, in particular, have shown great promise in image and speech recognition tasks.\n",
            "\n",
            "3. **Natural Language Processing:** Natural language processing has emerged as a key area of research, with applications in virtual assistants, chatbots, and language translation. AI-powered virtual assistants, for example, are being integrated into various devices, revolutionizing how we interact with technology.\n",
            "\n",
            "4. **Computer Vision:** Computer vision has become a critical component of AI systems, enabling applications in image recognition, object detection, and surveillance. AI-powered surveillance systems, for instance, are being used in various settings to improve safety and security.\n",
            "\n",
            "5. **Future Directions:** Experts predict that AI will continue to evolve, with a focus on explainable AI, transparency, and accountability. This shift in focus is aimed at addressing concerns about AI ethics and ensuring that AI systems are more trustworthy and secure.\n",
            "\n",
            "This study also identified several challenges facing the development of AI, including:\n",
            "\n",
            "1. **Data Quality and Availability:** The lack of high-quality data and availability of large datasets remains a significant challenge in the development of AI systems. Ensuring access to high-quality data is critical for developing effective AI systems.\n",
            "\n",
            "2. **Bias and Ethics:** AI systems can perpetuate biases and discriminatory practices, raising ethical concerns. Ensuring that AI systems are fair, transparent, and free from bias is critical.\n",
            "\n",
            "3. **Security and Cybersecurity:** AI systems can be vulnerable to cyber-attacks and data breaches, compromising their security and integrity. Ensuring that AI systems are secure and that data is protected is critical.\n",
            "\n",
            "Conclusion:\n",
            "\n",
            "This research provides a comprehensive review of the current state of AI, identifying key areas of research, challenges, and potential solutions. The findings of this study contribute to the development of more advanced and efficient AI systems, enabling the creation of innovative solutions for real-world problems. By addressing the challenges facing the development of AI, this study aims to inform policy and strategy and enable the development of AI systems that are trustworthy, secure, and transparent.\u001b[00m\n",
            "Exploring the Frontiers of Artificial Intelligence: A Comprehensive Review of Current Trends and Developments\n",
            "\n",
            "Abstract:\n",
            "\n",
            "In recent years, Artificial Intelligence (AI) has experienced exponential growth, permeating various aspects of modern life. This research paper provides a comprehensive review of the current state of AI, delving into the underlying concepts, methodologies, and future prospects. By examining existing literature and conducting expert interviews, this study identifies key areas of research, challenges, and potential solutions, with a focus on innovations that can drive AI system development.\n",
            "\n",
            "Introduction:\n",
            "\n",
            "The emergence of Artificial Intelligence (AI) as a transformative technology has been marked by its increasing applications in various industries, revolutionizing how we live and work. The growth of AI has been facilitated by the convergence of technologies, such as computing power, data storage, and algorithms, with AI now being an integral part of our daily lives. From intelligent assistants like Siri and Alexa to self-driving cars and personalized medicine, AI is changing the world.\n",
            "\n",
            "The increasing availability of large datasets, advances in deep learning techniques, and improvements in computing power have enabled the creation of more sophisticated AI systems. These advancements have led to the development of various AI applications, including expert systems, decision support systems, and virtual assistants, in industries such as healthcare, finance, education, and transportation.\n",
            "\n",
            "This research aims to provide a comprehensive review of the current state of AI, exploring its underlying concepts, applications, and future directions. By examining the current state of AI and its future directions, this study aims to contribute to the development of more advanced and efficient AI systems, enabling the creation of innovative solutions for real-world problems.\n",
            "\n",
            "Methodology:\n",
            "\n",
            "This research employed a comprehensive review of existing literature on AI, focusing on current trends and developments. A thorough search of reputable journals and conferences was conducted, covering articles, research papers, and books published over the past five years. The search keywords included \"Artificial Intelligence,\" \"Machine Learning,\" \"Natural Language Processing,\" and \"Computer Vision.\" This exhaustive search ensured that this study captured the current state of knowledge in AI.\n",
            "\n",
            "In addition to the literature review, this research included interviews with 20 experts in the field of AI, representing academia, industry, and research institutions. The expert interviews were semi-structured, aimed at gathering insights into the current state of AI, its challenges, and future directions. These interviews provided valuable additional information, enabling this study to delve deeper into the complexities and challenges of AI.\n",
            "\n",
            "Results:\n",
            "\n",
            "The review of existing literature and expert interviews revealed several key findings:\n",
            "\n",
            "1. **Current Applications of AI:** AI has been applied in various industries, including healthcare, finance, education, and transportation. AI applications in these industries have the potential to create unprecedented value.\n",
            "\n",
            "2. **Machine Learning and Deep Learning:** Machine learning and deep learning techniques have become essential components of AI systems, enabling the creation of more sophisticated models. Deep learning techniques, in particular, have shown great promise in image and speech recognition tasks.\n",
            "\n",
            "3. **Natural Language Processing:** Natural language processing has emerged as a key area of research, with applications in virtual assistants, chatbots, and language translation. AI-powered virtual assistants, for example, are being integrated into various devices, revolutionizing how we interact with technology.\n",
            "\n",
            "4. **Computer Vision:** Computer vision has become a critical component of AI systems, enabling applications in image recognition, object detection, and surveillance. AI-powered surveillance systems, for instance, are being used in various settings to improve safety and security.\n",
            "\n",
            "5. **Future Directions:** Experts predict that AI will continue to evolve, with a focus on explainable AI, transparency, and accountability. This shift in focus is aimed at addressing concerns about AI ethics and ensuring that AI systems are more trustworthy and secure.\n",
            "\n",
            "This study also identified several challenges facing the development of AI, including:\n",
            "\n",
            "1. **Data Quality and Availability:** The lack of high-quality data and availability of large datasets remains a significant challenge in the development of AI systems. Ensuring access to high-quality data is critical for developing effective AI systems.\n",
            "\n",
            "2. **Bias and Ethics:** AI systems can perpetuate biases and discriminatory practices, raising ethical concerns. Ensuring that AI systems are fair, transparent, and free from bias is critical.\n",
            "\n",
            "3. **Security and Cybersecurity:** AI systems can be vulnerable to cyber-attacks and data breaches, compromising their security and integrity. Ensuring that AI systems are secure and that data is protected is critical.\n",
            "\n",
            "Conclusion:\n",
            "\n",
            "This research provides a comprehensive review of the current state of AI, identifying key areas of research, challenges, and potential solutions. The findings of this study contribute to the development of more advanced and efficient AI systems, enabling the creation of innovative solutions for real-world problems. By addressing the challenges facing the development of AI, this study aims to inform policy and strategy and enable the development of AI systems that are trustworthy, secure, and transparent.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmkHan4NvbZh"
      },
      "id": "zmkHan4NvbZh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}