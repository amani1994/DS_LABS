{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "45fbb33b",
      "metadata": {
        "id": "45fbb33b"
      },
      "source": [
        "# LangChain Tutorial Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34a0df42",
      "metadata": {
        "id": "34a0df42"
      },
      "source": [
        "\n",
        "In this notebook, you will practice using LangChain to interact with large language models (LLMs),\n",
        "build chains, agents, and utilize memory. Fill in the code blocks with your implementations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "169dd23c",
      "metadata": {
        "id": "169dd23c"
      },
      "source": [
        "## Exercise 1: Basic LLM Query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf03f4a7",
      "metadata": {
        "id": "bf03f4a7"
      },
      "source": [
        "In this exercise, you will set up a basic interaction with the GROQ LLaMA model using LangChain.\n",
        "\n",
        "1. Initialize the LLM (Use GROQ and chose LLM).\n",
        "2. Create a prompt that asks the LLM to generate a story about a topic.\n",
        "3. Run the LLM chain to retrieve the response.\n",
        "\n",
        "**Steps**:\n",
        "- Import required modules from `langchain`.\n",
        "- Initialize the LLM with your GROQ API key.\n",
        "- Create a prompt template that takes a topic as input.\n",
        "- Create an LLM Chain and run it to get a response.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5686ae2f",
      "metadata": {
        "id": "5686ae2f",
        "outputId": "54807b70-94c0-4982-c359-ed9c59b2e6af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.10/dist-packages (6.2.11)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.121)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.5.2)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.11.0)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Requirement already satisfied: primp>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (0.6.2)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy) (2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community langchain-groq duckduckgo-search geopy requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key = \"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\""
      ],
      "metadata": {
        "id": "JL9d5hfHzYaH"
      },
      "id": "JL9d5hfHzYaH",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.8,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    api_key=groq_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "aXJsXpKx0EoA"
      },
      "id": "aXJsXpKx0EoA",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Define the prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"المرور\"],\n",
        "    template=\"Write a short story about {المرور في الرياض}.\"\n",
        ")"
      ],
      "metadata": {
        "id": "Mxijc4aP01rd"
      },
      "id": "Mxijc4aP01rd",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "# Create an LLM chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain with a specific topic\n",
        "response = chain.run(\"المرور في الرياض\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "6WLerdM31Iq1",
        "outputId": "ed754cbb-92dd-4fe5-f961-df27a9972f10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6WLerdM31Iq1",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-14429c4dc79d>:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n",
            "<ipython-input-5-14429c4dc79d>:7: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
            "  response = chain.run(\"المرور في الرياض\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "كان يوم ساخنًا في مدينة الرياض، أشعة الشمس الساخنة تسطع من السماء، وجم백رة من الناس على الشوارع بحثًا عن طعامهم وسياراتهم. بينما كان المرورون يتنقلون من خلال شوارع المدينة، كانوا يعرقلون بعضهم البعض في الطرق.\n",
            "\n",
            "كان تامر قد قام بحضور المعرض التجاري في الرياض، كان لديه بعض المنتجات التي يود bánها، فقرر أن يذهب إلى منطقة المليون، وهي المنطقة الأكثر تجمعًا في المدينة، حيث يمكنه بيع منتجاته بسهولة.\n",
            "\n",
            "بينما كان تامر يتنقل من خلال الشارع، واجهproblem في الطريق، كان هناك من أمامه ويعبر الطريق بشكل غير قانوني، فقرر تامر أن يتراجع قليلاً ليتجنب الصادم.\n",
            "\n",
            "لكن الفضول قد أثار في تامر، فقرر أن يتابع السيارة التي كانت تتعبر من على الجانب الآخر، بينما كان يتابعها، صدم صدمة عظيمة، فاطلق تامر صياحًا في وجهه.\n",
            "\n",
            "مروراً بفصيلة الشرطة، الذي حاول إحتواء الوضع، بينما كان تامر يصرخ في وجهه، ففوجئ أن الشرطي يبتسم له.\n",
            "\n",
            "- ما اللي بيكون بيهليني، يا حواجة؟ - قال الشرطي.\n",
            "\n",
            "- هي قمت بتصادم مع سيارة، وأنا لسه في حالة من الذعر - قال تامر.\n",
            "\n",
            "- آسف يا عم، لكنك مش بمشكل، الساده كانوا يخطئوا ويوصلوا، بالتعاون بيننا وبينهم، صحنا وتم إحضار سيارةك من مكانها وتم إرسالها إلى وكالة تأمين السيارات - قال الشرطي.\n",
            "\n",
            "- بالفعل، شكراً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "في ذلك اليوم، تمنى تامر أن يكون قد سكن في مكان آخر، حيث لا يتأثر بالازدحام والمشاكل.\n",
            "\n",
            "- السيد تامر، فيا مرحباً - قال الشرطي، وهم يبتعد عن مكان الحادث.\n",
            "\n",
            "- مرحباً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "- إنت وترجع، وإنا مشغولين - قال الشرطي.\n",
            "\n",
            "- بالفعل، شكراً يا أبو الفضيل، أعرف بيدك - قال تامر.\n",
            "\n",
            "- تمناً لك الخير، ونتمنى لك يومًا عظيمًا - قال الشرطي.\n",
            "\n",
            "- شكراً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "في تلك اللحظة، تمنى تامر أن يكون قد قام بشيء آخر، شيئًا يجعله يحيا في مدينة أخرى، حيث لا يجد مشاكل في الحياة.\n",
            "\n",
            "- السيد تامر، ويا مرحباً - قال الشرطي.\n",
            "\n",
            "- مرحباً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "- فيا ماذا؟ سأل أبو الفضيل تامر.\n",
            "\n",
            "- كلامي، أريد أكون في مكان آخر - قال تامر.\n",
            "\n",
            "- تصدق، لا تقل ليا كده - قال أبو الفضيل.\n",
            "\n",
            "- صح، لكن بصراحة، عليا مشكل، وبالتالي إنت مش صعب عليك، صحني ولا تفوتني - قال تامر.\n",
            "\n",
            "- كلامك صحيح، وبالتالي إنت مش صعب عليك، لكن تمناً لك الخير، ونتمنى لك يومًا عظيمًا - قال أبو الفضيل.\n",
            "\n",
            "- شكراً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "- يا تامر، إنت وترجع، وإانا مشغولين - قال أبو الفضيل.\n",
            "\n",
            "- بالفعل، شكراً يا أبو الفضيل، أعرف بيدك - قال تامر.\n",
            "\n",
            "- تمناً لك الخير، ونتمنى لك يومًا عظيمًا - قال أبو الفضيل.\n",
            "\n",
            "- شكراً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "في تلك اللحظة، تمنى تامر أن يكون قد قام بشيء آخر، شيئًا يجعله يحيا في مدينة أخرى، حيث لا يجد مشاكل في الحياة.\n",
            "\n",
            "- السيد تامر، ويا مرحباً - قال الشرطي.\n",
            "\n",
            "- مرحباً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "- فيا ماذا؟ سأل أبو الفضيل تامر.\n",
            "\n",
            "- كلامي، أريد أكون في مكان آخر - قال تامر.\n",
            "\n",
            "- تصدق، لا تقل ليا كده - قال أبو الفضيل.\n",
            "\n",
            "- صح، لكن بصراحة، عليا مشكل، وبالتالي إنت مش صعب عليك، صحني ولا تفوتني - قال تامر.\n",
            "\n",
            "- كلامك صحيح، وبالتالي إنت مش صعب عليك، لكن تمناً لك الخير، ونتمنى لك يومًا عظيمًا - قال أبو الفضيل.\n",
            "\n",
            "- شكراً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "- يا تامر، إنت وترجع، وإانا مشغولين - قال أبو الفضيل.\n",
            "\n",
            "- بالفعل، شكراً يا أبو الفضيل، أعرف بيدك - قال تامر.\n",
            "\n",
            "- تمناً لك الخير، ونتمنى لك يومًا عظيمًا - قال أبو الفضيل.\n",
            "\n",
            "- شكراً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "في ذلك اليوم، تمنى تامر أن يكون قد سكن في مكان آخر، حيث لا يتأثر بالازدحام والمشاكل.\n",
            "\n",
            "- السيد تامر، ويا مرحباً - قال الشرطي.\n",
            "\n",
            "- مرحباً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "- فيا ماذا؟ سأل أبو الفضيل تامر.\n",
            "\n",
            "- كلامي، أريد أكون في مكان آخر - قال تامر.\n",
            "\n",
            "- تصدق، لا تقل ليا كده - قال أبو الفضيل.\n",
            "\n",
            "- صح، لكن بصراحة، عليا مشكل، وبالتالي إنت مش صعب عليك، صحني ولا تفوتني - قال تامر.\n",
            "\n",
            "- كلامك صحيح، وبالتالي إنت مش صعب عليك، لكن تمناً لك الخير، ونتمنى لك يومًا عظيمًا - قال أبو الفضيل.\n",
            "\n",
            "- شكراً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "- يا تامر، إنت وترجع، وإانا مشغولين - قال أبو الفضيل.\n",
            "\n",
            "- بالفعل، شكراً يا أبو الفضيل، أعرف بيدك - قال تامر.\n",
            "\n",
            "- تمناً لك الخير، ونتمنى لك يومًا عظيمًا - قال أبو الفضيل.\n",
            "\n",
            "- شكراً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "في تلك اللحظة، تمنى تامر أن يكون قد قام بشيء آخر، شيئًا يجعله يحيا في مدينة أخرى، حيث لا يجد مشاكل في الحياة.\n",
            "\n",
            "- السيد تامر، ويا مرحباً - قال الشرطي.\n",
            "\n",
            "- مرحباً يا أبو الفضيل - قال تامر.\n",
            "\n",
            "- فيا ماذا؟ سأل أبو الفضيل تامر.\n",
            "\n",
            "- كلامي، أريد أكون في مكان آخر - said Tamer.\n",
            "\n",
            "- تصدق، لا تقل ليا كده - said Abu Fadil.\n",
            "\n",
            "- صح، لكن بصراحة، عليا مشكل، وبالتالي إنت مش صعب عليك، صحني ولا تفوتني - said Tamer.\n",
            "\n",
            "- كلامك صحيح، وبالتالي إنت مش صعب عليك، لكن تمناً لك الخير، ونتمنى لك يومًا عظيمًا - said Abu Fadil.\n",
            "\n",
            "- شكراً يا أبو الفضيل - said Tamer.\n",
            "\n",
            "- يا تامر، إنت وترجع، وإانا مشغولين - said Abu Fadil.\n",
            "\n",
            "- بالفعل، شكراً يا أبو الفضيل، أعرف بيدك - said Tamer.\n",
            "\n",
            "- تمناً لك الخير، ونتمنى لك يومًا عظيمًا - said Abu Fadil.\n",
            "\n",
            "- شكراً يا أبو الفضيل - said Tamer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ff1b3fa",
      "metadata": {
        "id": "1ff1b3fa"
      },
      "source": [
        "## Exercise 2: Building a Conversational Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a6a1f26",
      "metadata": {
        "id": "4a6a1f26"
      },
      "source": [
        "\n",
        "In this exercise, you will create a conversational agent that can interact with a user, make decisions,\n",
        "and use external tools like a search tool.\n",
        "\n",
        "1. Define a tool.\n",
        "2. Create an agent that can decide whether to use the tool or interact with the LLM.\n",
        "3. Run the agent with various inputs.\n",
        "\n",
        "**Steps**:\n",
        "- Define the search tool using a function.\n",
        "- Initialize an agent using the tool and the LLM.\n",
        "- Run the agent with sample inputs.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchRun()"
      ],
      "metadata": {
        "id": "Nm5I3hmi1hJX"
      },
      "id": "Nm5I3hmi1hJX",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search.invoke({\"query\": \"كم عدد الصلوات في اليوم؟\"})"
      ],
      "metadata": {
        "id": "0-v-S8LA2PRD",
        "outputId": "f82e92d8-c6aa-4341-c867-b628963e7c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "id": "0-v-S8LA2PRD",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Get accurate Islamic Prayer Times Today, Salat Timings, Namaz and Azan Time (Athan) globally with IslamicFinder, the most trusted and reliable source of Islamic Prayer Time. Find Salat and Namaz timetable for Fajr Time, Dhuhr Time, Asr Time, Maghrib Time and Isha prayer time today مواقيت الصلاة. مواقيت الصلاة لليوم. Daily Prayer Times Prayer times today in مكة المكرمة,السعودية are Fajr Time 07:56 PM, Dhuhr Time 06:26 PM, Asr Time 03:42 PM Maghrib Time 12:17 PM and Isha time 06:07 AM. مواقيت الصلاة اليوم في مكه, السعودية. 01:03:01. الوقت المتبقي لأذان العَصر. الوقت الأن في مكه 2:40:56 PM. الأذان القادم: العَصر. وقت أذان العَصر: 3:43 مساءً. مواقيت الصلاة لليوم. Daily Prayer Times Prayer times today in القاهرة,مصر are Fajr Time 07:21 PM, Dhuhr Time 06:03 PM, Asr Time 03:21 PM Maghrib Time 11:51 AM and Isha time 05:39 AM. الفاكس: +96265602254. الموقع: شارع الرازي - جبل الحسين -عمان ، الأردن. ساعات العمل : من الأحد إلى الخميس، من الساعة 8:30 صباحا الى الساعة 3:30 مساء. اقرأ المزيد. تحميل التطبيق. يدعم إنترنت إكسبلورر 10+, جوجل ...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "# List of tools the agent can use\n",
        "tools = [search]\n",
        "\n",
        "# Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")"
      ],
      "metadata": {
        "id": "DgjVFJDJ20C4",
        "outputId": "520a2117-4975-497d-b35c-b2bc6c7c2f38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DgjVFJDJ20C4",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-081ce7f81471>:7: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\"Find info about Riyadh season\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "dOhyJBiW22Kz",
        "outputId": "4b846004-92f6-47c7-a9e4-7d6bcf8956f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dOhyJBiW22Kz",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The official date for Riyadh Season 2024 is Saturday, October 12, 2024.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf94d2f",
      "metadata": {
        "id": "3cf94d2f"
      },
      "source": [
        "## Exercise 3: Using LLM as Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53ff48d9",
      "metadata": {
        "id": "53ff48d9"
      },
      "source": [
        "\n",
        "In this exercise, you will use an LLM to summarize and retain information from conversations.\n",
        "\n",
        "1. Set up LLM-based memory.\n",
        "2. Create a conversation with the LLM and memory.\n",
        "3. Ask follow-up questions using memory to retrieve past context.\n",
        "\n",
        "**Steps**:\n",
        "- Initialize summarization-based memory.\n",
        "- Run a few queries and retrieve responses.\n",
        "- Ask follow-up questions that reference previous interactions.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "796557b9",
      "metadata": {
        "id": "796557b9",
        "outputId": "52ab4896-82e1-439c-bcd1-b6d238c5bafc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-e6e306a6b8d0>:11: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
            "  chain_with_buffer_memory = ConversationChain(llm=llm, memory=summary_memory)\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory import ConversationSummaryMemory\n",
        "from langchain import ConversationChain\n",
        "\n",
        "# Initialize summarization-based memory\n",
        "summary_memory = ConversationSummaryMemory(llm=llm)\n",
        "\n",
        "# Clear memory\n",
        "summary_memory.clear()\n",
        "\n",
        "# Create a chain with LLM and buffer memory\n",
        "chain_with_buffer_memory = ConversationChain(llm=llm, memory=summary_memory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a conversation\n",
        "res1 = chain_with_buffer_memory.run(\"Answer with short answer, give me a wrong sentence about AI\")\n",
        "res2 = chain_with_buffer_memory.run(\"Answer with short answer, give me a correcr sentence about AI\")\n",
        "res3 = chain_with_buffer_memory.run(\"From the previous conversations. What was these sentences and what is the True between them ?\")\n",
        "\n",
        "print(f'First Response: {res1}\\nSecond Response: {res2}\\nThird Response: {res3}')"
      ],
      "metadata": {
        "id": "E_ar35NT4Xio",
        "outputId": "9da73f4d-5351-4d5d-b6e4-1ba1c558c168",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "E_ar35NT4Xio",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Response: AIs are primarily fueled by solar energy.\n",
            "Second Response: AIs are primarily powered by electricity generated from various sources such as fossil fuels, nuclear power, or renewable energy, including solar and wind power.\n",
            "Third Response: The previous conversation was as follows:\n",
            "- Human: AIs are primarily fueled by solar energy.\n",
            "- AI: No, AIs are primarily powered by electricity generated from various sources such as fossil fuels, nuclear power, or renewable energy, including solar and wind power.\n",
            " \n",
            "The True statements are the following:\n",
            "1. The sentence \"AIs are primarily fueled by solar energy\" is not true.\n",
            "2. The statement \"AIs are primarily powered by electricity generated from various sources such as fossil fuels, nuclear power, or renewable energy, including solar and wind power\" is true.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "630fe2fb",
      "metadata": {
        "id": "630fe2fb"
      },
      "source": [
        "## Exercise 4: Combining Tools and Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17dba76c",
      "metadata": {
        "id": "17dba76c"
      },
      "source": [
        "\n",
        "In this final exercise, you will build an intelligent agent that can use both tools (like an API) and memory.\n",
        "\n",
        "1. Define an external tool (like a weather API).\n",
        "2. Set up an agent that uses both the tool and LLM memory.\n",
        "3. Interact with the agent, combining memory and external data.\n",
        "\n",
        "**Steps**:\n",
        "- Define a weather API tool (mock or real API).\n",
        "- Initialize the agent with memory and the tool.\n",
        "- Run the agent with inputs, and check how it uses both memory and tools.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from geopy.geocoders import Nominatim\n",
        "\n",
        "def get_weather_by_city(city_name: str):\n",
        "    # Initialize geocoder\n",
        "    geolocator = Nominatim(user_agent=\"LLMexercise\")\n",
        "\n",
        "    # Get location data (latitude and longitude) for the city\n",
        "    location = geolocator.geocode(city_name)\n",
        "\n",
        "    if location:\n",
        "        latitude = location.latitude\n",
        "        longitude = location.longitude\n",
        "    else:\n",
        "        return f\"City '{city_name}' not found.\"\n",
        "\n",
        "    # Open-Meteo API endpoint with the obtained latitude and longitude\n",
        "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true\"\n",
        "\n",
        "    # Send a GET request to the Open-Meteo API\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the JSON data from the response\n",
        "        weather_data = response.json()\n",
        "\n",
        "        # Extract relevant information from the response\n",
        "        current_weather = weather_data.get('current_weather', {})\n",
        "        temperature = current_weather.get('temperature')\n",
        "        windspeed = current_weather.get('windspeed')\n",
        "        winddirection = current_weather.get('winddirection')\n",
        "        weather_time = current_weather.get('time')\n",
        "\n",
        "        # Return the weather information as a formatted string\n",
        "        return (\n",
        "            f\"Current weather in {city_name}:\\n\"\n",
        "            f\"Temperature: {temperature}°C\\n\"\n",
        "            f\"Wind Speed: {windspeed} m/s\\n\"\n",
        "            f\"Wind Direction: {winddirection}°\\n\"\n",
        "            f\"Time of data: {weather_time}\"\n",
        "        )\n",
        "    else:\n",
        "        return \"Failed to retrieve weather data.\""
      ],
      "metadata": {
        "id": "fOmjIOv6mzIq"
      },
      "id": "fOmjIOv6mzIq",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5e11ad68",
      "metadata": {
        "id": "5e11ad68"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "weather = Tool(\n",
        "    name=\"weather\",\n",
        "    func=get_weather_by_city,\n",
        "    description=\"Gets the weather of a city.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "# List of tools the agent can use\n",
        "tools = [weather]\n",
        "\n",
        "# Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")"
      ],
      "metadata": {
        "id": "TGwGflmUmBIw"
      },
      "id": "TGwGflmUmBIw",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\"What is the weather in Makkah Saudi Arabia?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "nLRMBWwjmZ4Q",
        "outputId": "4598bd94-959b-4632-e021-7ba4a4319cca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nLRMBWwjmZ4Q",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Makkah+Saudi+Arabia&format=json&limit=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current weather in Makkah Saudi Arabia is:\n",
            "Temperature: 31.5°C\n",
            "Wind Speed: 8.3 m/s\n",
            "Wind Direction: 214°\n",
            "Time of data: 2024-09-17T06:15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "akcA_Srhn7nT"
      },
      "id": "akcA_Srhn7nT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}